{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch[0.1],loss:1.7010454078248427\n",
      "epoch[1.1],loss:1.3988107834499919\n",
      "epoch[2.1],loss:1.2684714699966055\n",
      "epoch[3.1],loss:1.1706324803928343\n",
      "epoch[4.1],loss:1.08646242022133\n",
      "epoch[5.1],loss:1.0147035670105036\n",
      "epoch[6.1],loss:0.9577579523841311\n",
      "epoch[7.1],loss:0.9016604181939184\n",
      "epoch[8.1],loss:0.8536694773442457\n",
      "epoch[9.1],loss:0.8089555060718583\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m correct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     63\u001b[0m total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img,label \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     66\u001b[0m         output\u001b[38;5;241m=\u001b[39mmodel(img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t=transforms.Compose([transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    "                      )\n",
    " \n",
    "train_data=CIFAR10(root='./cifar',train=True,download=True,transform=t)\n",
    "test_data=CIFAR10(root='./cifar',train=False,download=True,transform=t)\n",
    "\n",
    "train_loader=DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=32,shuffle=False)\n",
    "\n",
    "class cnnmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnnmodel,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,32,3,padding=1)\n",
    "        self.conv2=nn.Conv2d(32,64,3,padding=1)\n",
    "        self.conv3=nn.Conv2d(64,128,3,padding=1)\n",
    "        self.fc1=nn.Linear(128*4*4,256)\n",
    "        self.fc2=nn.Linear(256,128)\n",
    "        self.fc3=nn.Linear(128,10)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=F.relu(x)\n",
    "        x=self.pool(x)\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        x=x.view(-1,128*4*4)\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model=cnnmodel()\n",
    "criterian=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.0001)\n",
    "\n",
    "#train the model\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss=0.0\n",
    "    for image,label in train_loader:\n",
    "        output=model(image)\n",
    "        loss=criterian(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "    print(f'epoch[{epoch+1/num_epochs}],loss:{running_loss/len(train_loader)}')\n",
    "\n",
    "model.eval()\n",
    "correct=0.0\n",
    "total=0.0\n",
    "with torch.no_grad:\n",
    "    for img,label in test_loader:\n",
    "        output=model(img)\n",
    "        loss=criterian(output,label)\n",
    "        _,predicted=torch.max(output,1)\n",
    "        total+=label.size(0)\n",
    "        running_loss+=loss.item()\n",
    "    print(f'epoch[{epoch+1/num_epochs}],loss:{running_loss/len(train_loader)}')\n",
    "    print(f\"accuracy:{(correct/total)*100}\")\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
